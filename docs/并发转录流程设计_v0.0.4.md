<!-- 备忘录
- 一个模型只能处理一个转录文件
- 模型加载与转录过程分离
- 转录结束后及时释放显存
- 动态选择下一个可加载的模型
-->

## 项目启动规范

### 程序运行命令
- **必须使用以下命令启动主程序**：
  ```powershell
  conda activate Xinference; python app.py
  ```
### 环境要求
- **必须在Xinference环境下运行**；
- **必须使用conda activate Xinference激活环境**；

### 请使用中文解释输出步骤。

# 并发转录流程设计方案（修订版）

## 1. 设计目标

设计一个基于GPU剩余显存动态决策的并发转录流程，考虑到Whisper的限制：
- 一个模型只能处理一个转录文件
- 模型加载与转录过程分离
- 转录结束后及时释放显存
- 动态选择下一个可加载的模型

## 2. 限制条件说明

### 2.1 Whisper核心限制
- **模型-文件一对一**：每个模型实例只能处理一个音频文件
- **模型独占性**：同一模型在任一时刻只能被一个任务使用
- **显存占用**：模型加载后会占用相应显存直到任务完成

### 2.2 系统约束
- **并发控制**：需要控制同时运行的模型数量
- **资源管理**：合理分配GPU资源避免冲突
- **任务调度**：在有限资源下最大化吞吐量

## 3. 流程设计原理

### 3.1 核心思想
- **模型级并发**：以模型为单位进行并发控制
- **任务级调度**：以任务为单位进行排队和调度
- **资源感知调度**：根据可用显存决定任务执行顺序

### 3.2 关键要素
1. **模型状态管理**：跟踪哪些模型正在使用中
2. **任务队列管理**：按优先级和资源需求组织任务
3. **显存动态评估**：实时评估显存状况
4. **任务分配策略**：合理分配任务到可用模型

## 4. 详细流程设计

### 4.1 任务状态机（修正版）

```
[Pending] → [Loading] → [Processing] → [Completed/Failed]
    ↑           ↑           ↑
    |           |           |
    └───[Resource Check]───[Release Resource]
```

### 4.2 模型使用状态管理（简化版）

由于取消模型复用，不再需要复杂的模型状态跟踪，因此简化为：
- 每个任务独立加载自己的模型实例
- 转录结束后及时释放显存
```

### 4.3 显存决策流程（修正版）

#### 步骤1：任务到达
```
1. 任务进入等待队列
2. 检查当前GPU运行任务数
3. 检查是否有模型正在加载
4. 进入资源评估阶段
```

#### 步骤2：资源评估
```
1. 获取GPU实时显存信息
2. 计算当前可用显存
3. 预估任务所需显存
4. 决策是否可以立即执行
```

#### 步骤3：模型加载决策（简化版）
```
输入：任务信息、GPU显存状态
输出：是否可以执行、分配的GPU

决策逻辑：
1. 如果当前无运行任务：
   - 检查显存是否足够加载任务模型
   - 如果足够，立即加载并执行
   - 如果不足，等待或排队

2. 如果已有运行任务：
   - 检查显存是否足够加载新模型
   - 如果可以，启动新任务
   - 如果不可以，排队等待
```

#### 步骤4：转录执行（修正版）
```
1. 全部都重新需要加载，转录结束后及时释放显存
2. 如果需要加载，执行模型加载
3. 发送loading状态更新
4. 启动转录任务
5. 实时监控转录进度（30秒间隔）
6. 转录完成后进入释放阶段
```

#### 步骤5：资源释放与下一任务决策
```
1. 转录任务完成
2. 释放相关模型显存
3. 标记模型为非活跃状态
4. 检查队列中是否有等待任务
5. 根据新资源状况决定是否启动新任务
6. 重复决策循环
```


### 7.2 资源感知调度
- 根据显存状况动态调整任务执行
- 避免显存不足导致的阻塞
- 提高资源利用率

### 7.3 并发度控制,多GPU调度
- 控制同时运行的模型数量
- 防止GPU资源过度竞争
- 保证系统稳定性

## 8. 实现要点（修订版）

### 8.1 状态同步保证
- 使用互斥锁确保模型状态一致性
- 实现状态变更的原子性操作
- 增加状态变更日志便于调试

### 8.2 错误处理机制
- 模型加载失败的回退机制
- 转录过程中异常的恢复处理
- 显存释放失败的重试机制

### 8.3 性能监控
- 实时监控显存使用率
- 记录模型加载时间统计
- 提供性能瓶颈分析工具

## 9. 预期效果（修订版）

1. **符合Whisper限制**：严格遵守一个模型一个文件的原则
2. **提高资源利用率**：通过模型复用减少加载开销
3. **增强系统稳定性**：合理的并发控制避免资源冲突
4. **改善用户体验**：更合理的任务调度和响应速度
5. **支持高并发处理**：在限制条件下最大化并发能力

## 10. 后续实施建议

1. **分阶段实现**：先实现基础版本，再逐步增加优化特性
2. **充分测试**：在不同硬件配置下进行压力测试
3. **监控告警**：建立完善的监控和告警机制
4. **文档完善**：详细记录设计思路和实现细节
5. **持续优化**：根据实际使用反馈不断优化算法

这个修订版的并发转录流程设计完全考虑了Whisper的限制条件，通过模型复用和智能调度，在保证系统稳定性的前提下最大化并发处理能力。
